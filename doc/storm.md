#Storm

人们通常想知道类似的系统比较。我们已经尽力对比与Samza相当的其他系统的特性集。但我们不是专家在这些框架方面,当然我们完全有偏见。如果我们有搞错,请让我们知道,我们会改正它。

Storm和Samza相当类似。两个系统都提供了许多相同的高级特性:分区流模型,分布式执行环境,流处理的API,容错,Kafka的集成等。

Storm和Samza使用不同的词来描述相似的概念:Storm中的Spout与Samza流消费者相似,bolt类似任务,元组类似于Samza消息。Storm也有一些额外的构建块在Samza没有直接的对应。

##Ordering and Guarantees

Storm允许您选择保证你想要处理的消息的级别:

- 最简单的方式是至多一次处理、发出的消息如果不能被正确处理,或如果机器处理失败。这种模式不需要特殊的逻辑,处理消息的顺序与它们产生的Spout一致。

- 还有至少一次处理,通过保持内存中的所有元组发出的记录，追踪是否每个输入元组(和任何下游生成的元组)在配置超时内成功处理。任何元组在超时时间内没有完全处理，则Spout重新发射。这意味着一个螺bolt可能看到相同的元组不止一次,消息处理将不能保证顺序。这种机制也需要一些用户代码操作,为了正确地确认它的输入必须保持记录的祖先。这在[Storm的wiki](https://github.com/nathanmarz/storm/wiki/Guaranteeing-message-processing)中做了深度的解释。

- 最后,Storm用Trident抽象来保证有且处理一次语义。这个模式使用相同的故障检测机制像至少一次模式。元组实际上是加工至少一次,但Storm的状态实现允许重复检测和忽略。(重复检测只适用于状态管理的Storm。如果您的代码有其他副作用,例如发送消息到服务之外的拓扑,它不会只有一次语义。)在这种模式下,Spout将输入流分成批次,按严格的顺序处理批次。

Samza也提供处理保证——目前只有至少一次发送,但只有一次语义在计划中。在每个流分区,Samza总是按在分区中出现的顺序处理消息,但没有保证不同输入流或分区之间的孙逊。这个模型允许Samza提供至少一次语义没有祖先跟踪的开销。Samza,不会有性能优势使用至多一次交付失败(即删除消息),这就是为什么我们不提供模式——消息传递总是得到保证。

此外,由于Samza从未处理一个信息无序分区,它更适合处理按关键字的数据。举个例子,如果你有一个数据库更新流,稍后更新可能取代更早更新,然后重新排序消息可能改变最终的结果。提供的所有更新相同的关键字出现在相同的流分区,Samza能够保证一致的状态。

##State Management

Storm的低级bolt API不提供任何在一个流的过程的状态管理。一个bolt可以维护状态在内存(如果bolt死亡将丢失),也可以调用远程数据库读写状态。然而,拓扑通常可以处理消息以更高的速度比调用一个远程数据库,因此远程调用每个消息迅速成为一个瓶颈。

作为高级TridentAPI的一部分,Storm提供自动状态管理。它在内存中保持状态,周期性的检查持久到远程数据库(例如Cassandra),因此远程数据库调用的成本跟数处理的元组数据一样。通过维护元数据和状态,Trient可以实现只有一次处理语义——例如,如果你是计数的事件,这种机制允许计数器是正确的,即使机器失败和元组重播。

Storm的缓存和批处理状态改变工作良好，如果在每个bolt的状态量相当小——也许小于100 kb。使其适应跟踪计数器,最小值,最大值和平均值的一个指标。然而,如果你需要维护大量的状态,这种方法本质上下降由于处理元组进行数据库调用,与相关的性能成本。

Samza状态管理采用一个完全不同的方法。它不是使用远程数据库持久存储,每个Samza任务包括嵌入式键值存储,位于同一台机器上。这种存储的读和写非常快,即使存储的内容大于可用内存。这个键值存储更改复制到集群中的其他机器,这样,如果一台机器挂了,任务的状态是在另一台机器上运行可以恢复。

通过共存的存储和处理在同一台机器上,Samza能够达到非常高的吞吐量,即使有大量的状态。这是必要的,如果你想执行状态操作,不只是计数器。例如,如果您想要执行一个窗口连接多个流,用一个数据库表或者加入一个流(复制到Samza通过“更改日志”),或一组几个相关消息到一个更大的消息,那么您需要维护这么多状态,它是更有效保持状态在本地任务。

Samza状态处理的一个局限是,目前不支持只有一次语义——现在只支持至少一次。但是我们正在努力解决,所以请继续关注更新。

##Partitioning and Parallelism

Storm的并行模型非常类似于Samza的。两个框架把处理分割成可以并行运行的独立任务。资源分配依赖于任务的数量:一个小的作业可以把所有的任务运行在一个单个机器上的进程,一个大的工作可以把任务运行在许多机器的多个进程中。

最大的区别是,Storm默认每个任务一个线程,而Samza使用单线程的进程(容器)。Samza容器可以包含多个任务,但只有一个线程循环的调用每个任务。这意味着每个容器映射到一个CPU核心,使资源模型更简单,减少运行在同一台机器上其他任务的干扰。Storm的多线程模型的优势更好地利用过剩闲置的机器,以较少的成本预测资源模型。

Storm支持动态调整并行度,这意味着为拓扑增加更多的线程或进程不会重新启动拓扑或集群。这是一个方便的特性,特别是在开发中。我们还没有添加这个特性到Samza:哲学上我们认为这种变化应该通过正常的配置管理过程(如版本控制、通知等)完成,因为它影响生产性能。换句话说,作业的代码和配置应充分再现集群的状态。

当Trident使用一个事务Spout(要求实现只有一次语义),并行性可能降低。Triden输入流t依赖全局顺序—也就是说,所有分区的流的顺序,而不仅仅是在一个分区。这意味着拓扑的输入流必须经历一个Spout实例,有效地忽略输入流的分区。这个spout在大容量下可能成为瓶颈。在Samza,所有流处理是并行的,没有这样的瓶颈。

##Deployment & Execution

Storm集群由一组运行Supervisor守护进程节点组成。supervisor守护进程与一个名为nimbus守护进程主节点通信。nimbus守护进程负责分配工作和管理集群中的资源。有关详细信息,请参阅Storm教程页面。这非常类似于YARN;尽管YARN有更多的功能并可扩展为其他框架,nimbus更好得与Storm集成。

Yahoo!也发布了Storm-YARN。在雅虎博客有介绍,Storm-YARN是一个包装器,把一个Storm集群(完整的nimubs,supervisor)整合在一个yarn网格中。

Storm的nimbus和YARN的ResourceManager有很多相似之处,以及Storm的supervisor和YARN的节点管理器之间也有很多相似。但不是写我们自己的资源管理框架,而是在YARN中运行,我们决定Samza应该直接使用YARN,YARN生态系统作为一个头等的公民。YARN是稳定的,只适应的,有很多特色,使用Hadoop的内部操作。它还提供了一些不错的特性,如安全(用户身份验证),cgroup处理隔离等。

Samza的YARN支持是可插拔的,所以如果你愿意你可以将它换成不同的执行框架。

##Language Support

Storm是用Java和Clojure编写的,但有很好的支持non-JVM语言支持。它遵循一个类似于MapReduce流的模式:non-JVM任务在一个单独的进程启动,数据发送给它的stdin,读取其stdout输出。

Samza是用Java和Scala编写的。它是建立多语言支持,但目前只支持JVM语言。

##Workflow

Storm提供了建模拓扑(多个阶段的加工图)的代码。Trident之上提供了一个进一步的高级API,包括类似的关系一样的操作如过滤器、分组、聚合和连接。这意味着整个拓扑连接在一个地方,它的优点是,它是记录在代码,但缺点是,整个拓扑需要开发和部署。

在Samza中,每个作业都是一个独立的实体。您可以定义多个作业在一个代码库,或者你可以有单独的团队工作在不同的作业使用不同的代码库。每个作业单独部署启动和停止。工作流只能通过命名流,您可以添加工作系统在不影响任何其他工作。这使得Samza适合处理数据流在一个大公司。

Samza的方法可以模拟在Storm通过代理连接两个不同的拓扑结构,如Kafka。然而,仅一次Storm的实现语义只能在一个拓扑。

##Maturity

我们不便评论Storm的成熟度,但它有一个众多的的用户数量,一个强大的特性集,似乎正在积极开发之中。它集成了许多常见的消息传递系统(RabbitMQ,Kestrel,Kafka等)。

Samza很不成熟,但它是建立在坚实的组件之上。YARN是相当新的,但是已经被雅虎运行在3000 +节点集群上!,该项目目前正在积极被Hortonworks和Cloudera开发。Kafka有很强一面,最近看到使用增加。这也是Storm大量用的原因。Samza是一个全新的项目,LinkedIn正在使用它。我们希望别人会觉得它有用,并采取它。

##Buffering & Latency

Storm使用ZeroMQ进行bolt之间非持久化的通信,使极低延迟传输元组。Samza还没有一个相应机制,总是写任务输出到流。

另一方面,当一个bolt使用ZeroMQ试图发送消息,并消费者读取消息速度不够快,ZeroMQ缓冲区在生产的过程中将填满信息。如果这个缓冲增长太多,拓扑的处理超时可能达到,导致消息被spout重新发射,使问题更糟糕的是通过添加更多的消息缓冲区。为了防止溢出,您可以配置一个最大数量的消息可以在拓扑处理中在任何一个时间,当达到这个门槛时,Spout停止发送,直到处理中的消息完全处理。这种机制允许背压,但需要精心配置topology.max.spout.pending。如果一个bolt在拓扑开始运行缓慢,处理在整个拓扑嘎然而止。

bolt之间缺乏一个代理来试图处理容错，这样增加了复杂性和消息传递语义。Storm有一个聪明的机制探测元组没有被处理,但Samza并不需要这样一个机制,因为每个输入和输出流都可以容错和复制。


Samza采用不同的方法来缓存。我们缓冲磁盘在StreamTask每一跳之间。这一决定,它的利弊,介绍的比较详细在描述页面。这种设计决策使得持久化保障容易,并允许缓冲的优势吸收大量积压的消息如果工作已经落后于其处理。然而,它导致略高的延迟代价。

如上面工作流部分所述,Samza的方法可以模拟Storm,但带有一个损失的功能。

##Isolation

Storm提供标准的UNIX进程级别的隔离。拓扑结构可能影响另一个拓扑的性能(或者相反)如果占用过多的CPU、磁盘、网络、内存等。

Samza依靠YARN提供资源级别隔离。目前,YARN提供了显式控制内存和CPU限制(通过cgroups),并且两者都与Samza成功使用。没有隔离磁盘或网络提供的YARN。

##Distributed RPC

在Storm中,您可以编写拓扑不仅接受固定事件流,但也允许客户按需运行分布式计算。查询作为一个元组发送到拓扑的一个特殊的Spout,然后拓扑计算答案,然后返回给客户端(谁是同步等待答案)。这称为“分布式RPC(DRPC)。

Samza目前没有一个DRPC等价的API,但是您可以使用Samza流处理原语构建它。

##Data Model

Storm模型所有元组的消息定义一个数据模型,使用可插拔的序列化。

Samza的序列化和数据模型都是可插拔的。我们不是非常固执己见的说哪种方法是最好的。